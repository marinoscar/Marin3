using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.Threading.Tasks;

namespace MarinApp.Agents
{
    /// <summary>
    /// Represents usage information for a Large Language Model (LLM) interaction.
    /// 
    /// This class tracks the provider and model used, as well as token usage statistics:
    /// <list type="bullet">
    /// <item>
    /// <description><see cref="Provider"/>: The name of the LLM service provider (e.g., OpenAI, Azure, etc.).</description>
    /// </item>
    /// <item>
    /// <description><see cref="Model"/>: The specific model identifier used for the request (e.g., "gpt-4").</description>
    /// </item>
    /// <item>
    /// <description><see cref="InputTokens"/>: The number of tokens sent as input to the model.</description>
    /// </item>
    /// <item>
    /// <description><see cref="OutputTokens"/>: The number of tokens generated by the model as output.</description>
    /// </item>
    /// <item>
    /// <description><see cref="TotalTokens"/>: The total number of tokens used (input + output).</description>
    /// </item>
    /// </list>
    /// 
    /// This information is useful for tracking usage, billing, and analytics related to LLM operations.
    /// </summary>
    public class LlmUsage
    {
        /// <summary>
        /// Gets the name of the LLM provider (e.g., "OpenAI", "Azure").
        /// </summary>
        public string Provider { get; init; } = "unknown";

        /// <summary>
        /// Gets the identifier of the LLM model used (e.g., "gpt-4").
        /// </summary>
        public string Model { get; init; } = "unknown";

        /// <summary>
        /// Gets the number of tokens sent as input to the model.
        /// </summary>
        public int InputTokens { get; init; } = 0;

        /// <summary>
        /// Gets the number of tokens generated by the model as output.
        /// </summary>
        public int OutputTokens { get; init; } = 0;

        /// <summary>
        /// Gets the total number of tokens used (input + output).
        /// </summary>
        public int TotalTokens { get; init; } = 0;

        /// <summary>
        /// Returns a string representation of the LLM usage, including provider and token counts.
        /// </summary>
        /// <returns>A formatted string with provider, input, output, and total tokens.</returns>
        public override string ToString()
            => $"{Provider} | in:{InputTokens} out:{OutputTokens} total:{TotalTokens}";
    }
}
